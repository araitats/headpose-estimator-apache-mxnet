{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet headpose in Tensorflow for DeepLens\n",
    "\n",
    "This notebook shows how to train an image classification model in Tensorflow on Amazon SageMaker and to prepare the trained model for AWS DeepLens deployment. \n",
    "The model used for this notebook is a RestNet model, trained with the headpose dataset.\n",
    "See the following papers for more background:\n",
    "\n",
    "[Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385.pdf) by Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun, Dec 2015.\n",
    "\n",
    "[Identity Mappings in Deep Residual Networks](https://arxiv.org/pdf/1603.05027.pdf) by Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun, Jul 2016.\n",
    "\n",
    "The following scripts are modified from Amazon SageMaker sample, [ResNet CIFAR-10 with tensorboard](https://github.com/awslabs/amazon-sagemaker-examples/tree/master/sagemaker-python-sdk/tensorflow_resnet_cifar10_with_tensorboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "s3_bucket = 'deeplens-sagemaker-0001'\n",
    "headpose_folder = 'headpose'\n",
    "\n",
    "#Bucket location to save your custom code in tar.gz format.\n",
    "custom_code_folder = 'customTFcodes'\n",
    "custom_code_upload_location = 's3://{}/{}/{}'.format(s3_bucket, headpose_folder, custom_code_folder)\n",
    "\n",
    "#Bucket location where results of model training are saved.\n",
    "model_artifacts_folder = 'TFartifacts'\n",
    "model_artifacts_location = 's3://{}/{}/{}'.format(s3_bucket, headpose_folder, model_artifacts_folder)\n",
    "\n",
    "#IAM execution role that gives SageMaker access to resources in your AWS account.\n",
    "#We can use the SageMaker Python SDK to get the role from our notebook environment. \n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a training job using the sagemaker.TensorFlow estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete source code\n",
    "- [resnet_model_headpose.py](resnet_model_headpose.py): ResNet model\n",
    "- [resnet_headpose.py](resnet_headpose.py): main script used for training and hosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "source_dir = os.path.join(os.getcwd())\n",
    "\n",
    "# AWS DeepLens currently supports TensorFlow version 1.4 (as of June 14th 2018). \n",
    "estimator = TensorFlow(entry_point='resnet_headpose.py',\n",
    "                       framework_version = 1.4,\n",
    "                       source_dir=source_dir,\n",
    "                       role=role,\n",
    "                       training_steps=25000, evaluation_steps=700,\n",
    "                       train_instance_count=1, \n",
    "                       base_job_name='deeplens-TF-headpose',\n",
    "                       output_path=model_artifacts_location,\n",
    "                       code_location=custom_code_upload_location,\n",
    "                       train_instance_type='ml.p2.xlarge',\n",
    "                       train_max_run = 432000,\n",
    "                       train_volume_size=100)\n",
    "\n",
    "\n",
    "# Head-pose dataset \"HeadPoseData_trn_test_x15_py2.pkl\" is in the following S3 folder. \n",
    "dataset_location = 's3://{}/{}/datasets'.format(s3_bucket, headpose_folder)\n",
    "\n",
    "estimator.fit(dataset_location)\n",
    "# Enabling Tensorboard. \n",
    "#estimator.fit(dataset_location, run_tensorboard_locally=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a frozen protobuff file (frozen_model.pb)\n",
    "The trained model artifact needs to be converted to a frozen protobuff format, which is supported by AWS DeepLens' model optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch a trained model artifact (model.tar.gz) from S3\n",
    "First, download model.tar.gz to the local folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "s3 = boto3.resource('s3')\n",
    "key = '{}/{}/{}/output/model.tar.gz'.format(headpose_folder, model_artifacts_folder,estimator.latest_training_job.name)\n",
    "print(key)\n",
    "s3.Bucket(s3_bucket).download_file(key,'model.tar.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may find a model.tar.gz in your local directry. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Untar the trained model artifact (model.tar.gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xvf model.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the model directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "model_dir = glob.glob('export/*/*')\n",
    "# The model directory looks like 'export/Servo/{Assigned by Amazon SageMaker}'\n",
    "print(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freeze the graph and save it in the frozen protobuff format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.tools import optimize_for_inference_lib\n",
    "def freeze_graph(model_dir, output_node_names):\n",
    "    \"\"\"Extract the sub graph defined by the output nodes and convert \n",
    "    all its variables into constant \n",
    "    Args:\n",
    "        model_dir: the root folder containing the checkpoint state file\n",
    "        output_node_names: a string, containing all the output node's names, \n",
    "                            comma separated\n",
    "    \"\"\"\n",
    "    \n",
    "    # We start a session using a temporary fresh Graph\n",
    "    with tf.Session(graph=tf.Graph()) as sess:\n",
    "        # We import the meta graph in the current default Graph\n",
    "        tf.saved_model.loader.load(sess, [tf.saved_model.tag_constants.SERVING], model_dir)\n",
    "\n",
    "        # We use a built-in TF helper to export variables to constants\n",
    "        input_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "            sess, # The session is used to retrieve the weights\n",
    "            tf.get_default_graph().as_graph_def(), # The graph_def is used to retrieve the nodes \n",
    "            output_node_names.split(\",\") # The output node names are used to select the usefull nodes\n",
    "        ) \n",
    "\n",
    "    # We generate the inference graph_def\n",
    "    output_graph_def = optimize_for_inference_lib.optimize_for_inference(tf.graph_util.remove_training_nodes(input_graph_def),\n",
    "                                                                         ['Const_1'], # an array of the input node(s)\n",
    "                                                                         output_node_names.split(\",\"), # an array of output nodes\n",
    "                                                                         tf.float32.as_datatype_enum)\n",
    "    # Finally we serialize and dump the output graph_def to the filesystem\n",
    "    with tf.gfile.GFile('frozen_model.pb', \"wb\") as f:\n",
    "            f.write(output_graph_def.SerializeToString())\n",
    "    print(\"tf magic!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_graph(model_dir[0], 'softmax_tensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should be noted that we knew the names of input and output nodes (i.e. Const_1 and softmax_tensor) by examining TensorBoard in advance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may find a frozen_model.pb in your local directry. Now you are ready to deploy the file to AWS DeepLens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put frozen_model.pb back to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open('frozen_model.pb', \"rb\")\n",
    "key = '{}/{}/{}/output/frozen_model.pb'.format(headpose_folder, model_artifacts_folder,estimator.latest_training_job.name)\n",
    "s3.Bucket(s3_bucket).put_object(Key=key, Body=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('s3://{}/{}'.format(s3_bucket, key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# (Extra) Deploy the trained model to SageMaker Endpoint \n",
    "\n",
    "The deploy() method creates an endpoint which serves prediction requests in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = estimator.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a prediction with fake data to verify the endpoint is up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "random_image_data = np.random.rand(1,84, 84, 3)\n",
    "predictor.predict(random_image_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a prediction with a headpose image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import boto3\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import urllib\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "sample_ims_location = 'https://s3.amazonaws.com/deeplens-sagemaker-0001/headpose/testIMs/IMG_1242.jpeg'\n",
    "\n",
    "print(sample_ims_location)\n",
    "\n",
    "def download(url):\n",
    "    filename = url.split(\"/\")[-1]\n",
    "    if not os.path.exists(filename):\n",
    "        urllib.urlretrieve(url, filename)\n",
    "    print(filename)\n",
    "    return cv2.imread(filename).astype(np.float32)\n",
    "        \n",
    "im_true = download(sample_ims_location)\n",
    "\n",
    "im = im_true.astype(np.float32)/255.0 # Normalized\n",
    "\n",
    "crop_uly = 62\n",
    "crop_height = 360\n",
    "crop_ulx = 100\n",
    "crop_width = 360\n",
    "\n",
    "im = im[crop_uly:crop_uly + crop_height, crop_ulx:crop_ulx + crop_width]\n",
    "im_crop = im\n",
    "plt.imshow(im_crop[:,:,::-1])\n",
    "plt.show()\n",
    "\n",
    "im = cv2.resize(im, (84, 84))\n",
    "\n",
    "plt.imshow(im[:,:,::-1])\n",
    "plt.show()\n",
    "\n",
    "print(im.shape)\n",
    "im = np.expand_dims(im, axis=0)\n",
    "print(im.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.predict(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning up\n",
    "To avoid incurring charges to your AWS account for the resources used in this tutorial you need to delete the **SageMaker Endpoint:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker.Session().delete_endpoint(predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p27",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
